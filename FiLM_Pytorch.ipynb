{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "CVrfBJ9ExkAH"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def conv(input_channels, output_channels, kernel_size, strides, padding):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(input_channels, output_channels, kernel_size, strides, padding),\n",
        "        nn.ReLU(inplace = True),\n",
        "        nn.BatchNorm2d(output_channels)\n",
        "    )"
      ],
      "metadata": {
        "id": "Amz_cTexxsi3"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FeatureExtractor(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.convs = nn.Sequential(\n",
        "            conv(input_channels = 3,\n",
        "                 output_channels = 128,\n",
        "                 kernel_size = 4,\n",
        "                 strides = 2,\n",
        "                 padding = 1), #112x112\n",
        "            conv(input_channels = 128,\n",
        "                 output_channels = 128,\n",
        "                 kernel_size = 4,\n",
        "                 strides = 2,\n",
        "                 padding = 1), #56x56\n",
        "            conv(input_channels = 128,\n",
        "                 output_channels = 128,\n",
        "                 kernel_size = 4,\n",
        "                 strides = 2,\n",
        "                 padding = 1), #28x28\n",
        "            conv(input_channels = 128,\n",
        "                 output_channels = 128,\n",
        "                 kernel_size = 4,\n",
        "                 strides = 2,\n",
        "                 padding = 1), #14x14\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.convs(x)\n"
      ],
      "metadata": {
        "id": "PnO3OTGazFbp"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FilmBlock(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x, beta, gamma ):\n",
        "\n",
        "        beta = beta.view(x.size(0), x.size(1), 1, 1)\n",
        "        gamma = gamma.view(x.size(0), x.size(1), 1, 1)\n",
        "\n",
        "        return x * gamma + beta #hadamard product"
      ],
      "metadata": {
        "id": "FxttblUu9G5B"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResBlock(nn.Module):\n",
        "    def __init__(self, input_channels, output_channels):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels = self.input_channels,\n",
        "                               out_channels = self.output_channels,\n",
        "                               kernel_size = 1,\n",
        "                               stride = 1,\n",
        "                               padding = 0)\n",
        "        self.relu1 = nn.ReLU(inplace = True)\n",
        "        self.conv2 = nn.Conv2d(in_channels = output_channels,\n",
        "                               out_channels = output_channels,\n",
        "                               kernel_size = 3,\n",
        "                               stride = 1,\n",
        "                               padding = 1)\n",
        "        self.batchnorm = nn.BatchNom2d(output_channels)\n",
        "\n",
        "        self.film = self.FilmBlock()\n",
        "        self.relu2 = nn.ReLU(inplace = True)\n",
        "\n",
        "    def forward(self, x, beta, gamma):\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu1(x)\n",
        "\n",
        "        identity = x\n",
        "\n",
        "        y = self.conv2(x)\n",
        "        y = self.batchnorm(y)\n",
        "        y = self.film(y, beta, gamma)\n",
        "        y = self.relu2(y)\n",
        "\n",
        "        y = y + identity\n",
        "\n",
        "        return y\n"
      ],
      "metadata": {
        "id": "pgOd6lwf_I9w"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Classifier(nn.Module):\n",
        "    def __init__(self, input_channels, class_num):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv = nn.conv(in_channels = input_channels,\n",
        "                            out_channels = 512,\n",
        "                            kernel_size = 1,\n",
        "                            stride = 1,\n",
        "                            padding = 0)\n",
        "        self.maxpool = nn.AdaptiveMaxPool2d((1, 1))\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(512, 1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(1024,1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(1024, class_num)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "\n",
        "        x = self.maxpool(x)\n",
        "        x = x.view(x.size(0), x.size(1))\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "rLEvNEzXDIU9"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FiLM(nn.Module):\n",
        "    def __init__(self, n_vocab, embed_hidden, gru_hidden, res_blk_num, class_num, img_channels):\n",
        "        super().__init__()\n",
        "\n",
        "        dim_question = 11\n",
        "\n",
        "        self.embed = nn.Embedding(n_vocab, embed_hidden)\n",
        "        self.gru = nn.GRU(embed_hidden, gru_hidden, batch_first = True)\n",
        "        self.film_generator = nn.Linear(gru_hidden, 2 * res_blk_num * img_channels)\n",
        "\n",
        "        self.featureextractor = FeatureExtractor()\n",
        "        self.res_blks = nn.ModuleList() #동적으로 모듈을 추가하기 위해. res_blk의 갯수가 고정적이지 않기 때문에 사용해야함.\n",
        "\n",
        "        for _ in range(res_blk_num):\n",
        "            self.res_blks.append(ResBlock(img_channels + 2, img_channels)) #여기에서 왜 +2를 하는지?-> coordinate x, coordinate y도 주기 때문.\n",
        "\n",
        "        self.classifier = Classifier(img_channels, class_num)\n",
        "\n",
        "        self.res_blk_num = res_blk_num\n",
        "        self.img_channels = img_channels\n",
        "\n",
        "    def forward(self, x, question, question_len):\n",
        "        #x is image.\n",
        "\n",
        "        batch_size = x.size(0)\n",
        "\n",
        "        #1) Image Feature Extract\n",
        "        x = self.featureextractor(x)\n",
        "\n",
        "        #2) GRU의 output을 Linear 통과시켜 beta와 gamma를 구한다.\n",
        "        embed = self.embed(question)\n",
        "        embed = nn.utils.rnn.pack_padded_sequence(embed, question_len, batch_first=True)\n",
        "        _, h = self.gru(embed)\n",
        "        film_vector = self.film_generator(h.squeeze()).view(\n",
        "            batch_size, self.res_blk_num, 2, self.img_channels #여기에서 2는 gamma와 beta\n",
        "        )\n",
        "\n",
        "        d = x.size(2) #이미지 사이즈(width)\n",
        "\n",
        "\n",
        "        #3) 논문에서 spatial reasoning을 위해 각 resblock의 input으로\n",
        "        #   -1~1로 scale된 x와y spatial position을 image feature과 concat한다고 나와있음.\n",
        "        coordinate = torch.arange(-1, 1 + 0.00001, 2/(d-1)).cuda()\n",
        "        coordinate_x = coordinate.expand(batch_size, 1, d, d)\n",
        "        coordinate_y = coordinate.view(d, 1).expand(batch_size, 1, d, d)\n",
        "\n",
        "        #4) 각각의 ResBlock에 concat된 x와 beta, gamma를 입력한다.\n",
        "        for i, res_block in enumerate(self.res_blks):\n",
        "            beta = film_vector[:, i, 0, :] #batch_size, res_blk_num, beta, channel\n",
        "            gamma = film_vector[:, i, 1, :] #batch_size, res_blk_num, gamma, channel\n",
        "\n",
        "            x = torch.cat([x, coordinate_x, coordinate_y], dim=1)\n",
        "            x = res_block(x, beta, gamma)\n",
        "\n",
        "        #5) classifier\n",
        "        x = self.classifier(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rHasAdQ2GKyD"
      },
      "execution_count": 15,
      "outputs": []
    }
  ]
}